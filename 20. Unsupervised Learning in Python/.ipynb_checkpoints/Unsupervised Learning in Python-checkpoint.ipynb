{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 - Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > k-means clustering with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [[ 5.0, 3.3, 1.4, 0.2]\n",
    " [ 5.0, 3.5, 1.3, 0.3]\n",
    " [ 4.9, 2.4, 3.3, 1.0]\n",
    " [ 6.3, 2.8, 5.1, 1.5]\n",
    " [ 7.2, 3.2, 6.0, 1.8]]\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(samples)\n",
    "KMeans(algorithm='auto')\n",
    "labels = model.predict(samples)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Cluster labels for new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_samples)\n",
    "#[[ 5.7 4.4 1.5 0.4]\n",
    "# [ 6.5 3. 5.5 1.8]\n",
    "# [ 5.8 2.7 5.1 1.9]]\n",
    "new_labels = model.predict(new_samples)\n",
    "print(new_labels)\n",
    "#[0 2 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "xs = samples[:,0]\n",
    "ys = samples[:,2]\n",
    "plt.scatter(xs, ys, c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 - Evaluating a clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Aligning labels and species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'labels': labels, 'species': species})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Crosstab of labels and species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ct = pd.crosstab(df['labels'], df['species'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Inertia measures clustering quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(samples)\n",
    "print(model.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 - Transforming features for better clusterings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Clustering the wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3)\n",
    "labels = model.fit_predict(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Clusters vs. varieties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'labels': labels,'varieties': varieties})\n",
    "ct = pd.crosstab(df['labels'], df['varieties'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > sklearn StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(samples)\n",
    "samples_scaled = scaler.transform(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Pipelines combine multiple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline = make_pipeline(scaler, kmeans)\n",
    "pipeline.fit(samples)\n",
    "labels = pipeline.predict(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Feature standardization improves clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n",
    "ct = pd.crosstab(df['labels'], df['varieties'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 - Visualizing hierarchies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Hierarchical clustering with SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "mergings = linkage(samples, method='complete')\n",
    "dendrogram(mergings, labels=country_names,leaf_rotation=90,leaf_font_size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 - Cluster labels in hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Extracting cluster labels using fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "mergings = linkage(samples, method='complete')\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "labels = fcluster(mergings, 15, criterion='distance')\n",
    "print(labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Aligning cluster labels with country names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pairs = pd.DataFrame({'labels': labels,'countries': country_names})\n",
    "print(pairs.sort_values('labels')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 - t-SNE for 2-dimensional maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > t-SNE in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples)\n",
    "[[ 5. 3.3 1.4 0.2]\n",
    " [ 5. 3.5 1.3 0.3]\n",
    " [ 4.9 2.4 3.3 1. ]\n",
    " [ 6.3 2.8 5.1 1.5]\n",
    " [ 4.9 3.1 1.5 0.1]]\n",
    "print(species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(learning_rate=100)\n",
    "transformed = model.fit_transform(samples)\n",
    "xs = transformed[:,0]\n",
    "ys = transformed[:,1]\n",
    "plt.scatter(xs, ys, c=species)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 - Visualizing the PCA transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Using scikit-learn PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples)\n",
    "[[ 2.8 3.92]\n",
    " [ 2.65 3.4 ]\n",
    " [ 2.05 1.6 ]]\n",
    "from sklearn.decomposition import PCA\n",
    "model = PCA()\n",
    "model.fit(samples)\n",
    "transformed = model.transform(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 - Intrinsic dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Plotting the variances of PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(samples)\n",
    "features = range(pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xticks(features)\n",
    "plt.ylabel('variance')\n",
    "plt.xlabel('PCA feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 - Dimension reduction with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Dimension reduction of iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(samples)\n",
    "transformed = pca.transform(samples)\n",
    "print(transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Iris dataset in 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "xs = transformed[:,0]\n",
    "ys = transformed[:,1]\n",
    "plt.scatter(xs, ys, c=species)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > TruncatedSVD and csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "model = TruncatedSVD(n_components=3)\n",
    "model.fit(documents) # documents is csr_matrix\n",
    "transformed = model.transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 - Non-negative matrix factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Example usage of NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=2)\n",
    "model.fit(samples)\n",
    "nmf_features = model.transform(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 - NMF learns interpretable parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Applying NMF to the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(articles.shape)\n",
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=10)\n",
    "nmf.fit(articles)\n",
    "print(nmf.components_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Visualizing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample)\n",
    "bitmap = sample.reshape((2, 3))\n",
    "print(bitmap)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(bitmap, cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 - Building recommender systems using NMF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Apply NMF to the word-frequency array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=6)\n",
    "nmf_features = nmf.fit_transform(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Calculating the cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "norm_features = normalize(nmf_features)\n",
    "current_article = norm_features[23,:] # if has index 23\n",
    "similarities = norm_features.dot(current_article)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > DataFrames and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "norm_features = normalize(nmf_features)\n",
    "df = pd.DataFrame(norm_features, index=titles)\n",
    "current_article = df.loc['Dog bites man']\n",
    "similarities = df.dot(current_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 - Building recommender systems using NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Apply NMF to the word-frequency array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf = NMF(n_components=6)\n",
    "nmf_features = nmf.fit_transform(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > Calculating the cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "norm_features = normalize(nmf_features)\n",
    "current_article = norm_features[23,:] # if has index 23\n",
    "similarities = norm_features.dot(current_article)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### > DataFrames and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "norm_features = normalize(nmf_features)\n",
    "df = pd.DataFrame(norm_features, index=titles)\n",
    "current_article = df.loc['Dog bites man']\n",
    "similarities = df.dot(current_article)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
